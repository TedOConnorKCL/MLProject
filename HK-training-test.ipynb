{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D-CNNs for MNIST dataset\n",
    "* Learn about:\n",
    "    * [THE MNIST DATABASE](http://yann.lecun.com/exdb/mnist/)\n",
    "    * Coding with PyTorch Lightning\n",
    "        * LightningDataModule\n",
    "        * LightningModule\n",
    "        * (optional) Logger, Trainer, callbacks\n",
    "    * Two types of the artificial neuralnetworks\n",
    "        * Multilayer perceptron (MLP)\n",
    "        * 2D Convolutional neuralnetworks (2D CNNs)\n",
    "* Let's try:\n",
    "    * Build MLP or CNNs by yourself\n",
    "    * Try to use other loss functions\n",
    "    * Try to change the training parameters\n",
    "        * learning rate, batch size, epochs, etc..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1. Lightning data module for MNIST dataset ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `train_data`: 50,000\n",
    "* `test_data`: 10,000\n",
    "* `val_data`: 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from typing import Optional\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HKDataset(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size: int = 128,\n",
    "        num_workers: int = 2,\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.mean = ()\n",
    "        self.std = ()\n",
    "        self.trans = None\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        imgs = torch.load('/home/mlproject2024/ml_project/data/hyperk_img_128x128_small_v2/imgs_scaled.pt')\n",
    "        labels_targets = torch.load('/home/mlproject2024/ml_project/data/hyperk_img_128x128_small_v2/labels_targets_scaled.pt')\n",
    "        indices = torch.load('/home/mlproject2024/ml_project/data/hyperk_img_128x128_small_v2/indices.pt')\n",
    "\n",
    "        self.train_data = torch.utils.data.TensorDataset( imgs[indices['train']], labels_targets[indices['train']])\n",
    "        self.valid_data = torch.utils.data.TensorDataset( imgs[indices['valid']], labels_targets[indices['valid']])\n",
    "        self.test_data = torch.utils.data.TensorDataset( imgs[indices['test']], labels_targets[indices['test']])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.valid_data, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_data, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2-2. 2D-CNNs model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SpatialTransformerNetwork(nn.Module):\n",
    "    def __init__(self, input_size, num_channels):\n",
    "        super(SpatialTransformerNetwork, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 8, kernel_size=7),  \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),                 \n",
    "            nn.Conv2d(8, 10, kernel_size=5),           \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),                 \n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(1440, 32),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 6)  \n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(batch_size, -1)  \n",
    "        theta = self.fc_loc(xs)  \n",
    "        theta = theta.view(-1, 2, 3)  \n",
    "        \n",
    "        \n",
    "        grid = F.affine_grid(theta, x.size(), align_corners=False)\n",
    "        x = F.grid_sample(x, grid, align_corners=False)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class CNNs2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNs2D, self).__init__()\n",
    "        \n",
    "        self.stn = SpatialTransformerNetwork(input_size=(64, 64), num_channels=2) \n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=2, out_channels=32, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.fc_class_layer = nn.Sequential(\n",
    "            nn.Linear(128, 256),  \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 64),   \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 32),    \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 2),     \n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.fc_regression_layer = nn.Sequential(\n",
    "            nn.Linear(128, 256),  \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 64),   \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 32),    \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 4),    \n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        #x = self.stn(x)\n",
    "        #print('x0', x.shape)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print('x4', x.shape, x)\n",
    "        return [self.fc_class_layer(x), self.fc_regression_layer(x)]\n",
    "    \n",
    "class RMSLELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, pred, actual):\n",
    "        return torch.sqrt(self.mse(torch.log(pred+1), torch.log(actual+1)))\n",
    "    \n",
    "def rse_loss(pred, target):\n",
    "        return torch.sqrt(torch.sum((pred-target)**2)/torch.sum((target-torch.mean(target))**2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SpatialTransformerNetwork(nn.Module):\n",
    "    def __init__(self, input_size, num_channels):\n",
    "        super(SpatialTransformerNetwork, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 8, kernel_size=7),  \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),                 \n",
    "            nn.Conv2d(8, 10, kernel_size=5),           \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),                 \n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(1440, 32),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 6)  \n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(batch_size, -1)  \n",
    "        theta = self.fc_loc(xs)  \n",
    "        theta = theta.view(-1, 2, 3)  \n",
    "        \n",
    "        \n",
    "        grid = F.affine_grid(theta, x.size(), align_corners=False)\n",
    "        x = F.grid_sample(x, grid, align_corners=False)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class CNNs2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNs2D, self).__init__()\n",
    "        \n",
    "        self.stn = SpatialTransformerNetwork(input_size=(64, 64), num_channels=2) \n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(in_channels=2, out_channels = 16, kernel_size = 3, stride = 2, padding = 1, output_padding=1, bias = False)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.upconv2 = nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.upconv3 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(32768, 1024),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(1024, 512), \n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(512, 256),   \n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "        self.fc_class_layer = nn.Sequential(\n",
    "            nn.Linear(256,128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(128, 2),     \n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.fc_regression_layer = nn.Sequential(\n",
    "            nn.Linear(256,128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(128, 4),    \n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        #x = self.stn(x)\n",
    "        #print('x0', x.shape)\n",
    "        x = self.upconv1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.upconv2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.upconv3(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layer(x)\n",
    "        #print('x4', x.shape, x)\n",
    "        return [self.fc_class_layer(x), self.fc_regression_layer(x)]\n",
    "    \n",
    "class RMSLELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, pred, actual):\n",
    "        return torch.sqrt(self.mse(torch.log(pred+1), torch.log(actual+1)))\n",
    "    \n",
    "def rse_loss(pred, target):\n",
    "        return torch.sqrt(torch.sum((pred-target)**2)/torch.sum((target-torch.mean(target))**2))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3. Pytorch lightning module ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma = 5):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.ce_loss = nn.CrossEntropyLoss(reduction = 'none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = self.ce_loss(inputs, targets)\n",
    "        p_t = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1-p_t)**self.gamma*ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "class PLModuleMNIST(LightningModule):\n",
    "    def __init__(self, model, lr_rate):\n",
    "        super(PLModuleMNIST, self).__init__()\n",
    "        self.model = model\n",
    "        self.lr_rate = lr_rate\n",
    "        self.accuracy_calc = BinaryAccuracy(threshold=0.5)\n",
    "        self.focal_loss = FocalLoss(alpha = 0.5, gamma = 4.5)\n",
    "        self.automatic_optimization = False\n",
    "        self.loss_training = []\n",
    "        self.loss_valid = []\n",
    "        self.loss_training_epoch = []\n",
    "        self.loss_valid_epoch = []\n",
    "        \n",
    "        self.acc_training = []\n",
    "        self.acc_valid = []\n",
    "        self.acc_training_epoch = []\n",
    "        self.acc_valid_epoch = []\n",
    "\n",
    "    def forward(self, batch: Tensor, **kwargs) -> Tensor:\n",
    "        #print('batch:', batch.size)\n",
    "        return self.model(batch)\n",
    "\n",
    "    #def loss_fn(self, x, y):\n",
    "    #    #print('loss:x,y',x.shape, y.shape)\n",
    "    #    #print('type',x[0].dtype, y[0].dtype)\n",
    "    #    return F.nll_loss(x, y)\n",
    "    \n",
    "    #def loss_fn_regression(self, x, y):\n",
    "    #    #print(x[0][0], y[0][0])\n",
    "    #    loss_energy = F.l1_loss(x[:,0], y[:,0])\n",
    "    #    loss_position = F.l1_loss(x[:,1:4], y[:,1:4])\n",
    "    #    loss = loss_energy + loss_position\n",
    "    #    return loss\n",
    "\n",
    "\n",
    "    def loss_fn(self, x, y):\n",
    "        x_class=x[0]\n",
    "        y_class=torch.tensor(y[:,0], dtype=torch.int64)\n",
    "        \n",
    "        #print(y)\n",
    "        x_reg=x[1]\n",
    "        y_reg=y[:,1:]\n",
    "        \n",
    "        loss_class = self.focal_loss(x_class, y_class)\n",
    "        loss_energy = F.l1_loss(x_reg[:,0], y_reg[:,0])\n",
    "        loss_position = rse_loss(x_reg[:,1:4], y_reg[:,1:4])\n",
    "        loss = loss_class + loss_energy + loss_position\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        opt = self.optimizers()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        x, y = batch\n",
    "        label=torch.tensor(y[:,0], dtype=torch.int64)\n",
    "        #targets=y[:,1:5]\n",
    "        \n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss_fn(logits,y)\n",
    "        #loss = self.loss_fn(logits,y[:,0])\n",
    "        #loss = self.loss_fn_regression(logits,targets)\n",
    "        \n",
    "        acc = self.accuracy_calc(logits[0][:,1], label)\n",
    "        \n",
    "        self.manual_backward(loss)\n",
    "        opt.step()\n",
    "\n",
    "        self.loss_training.append(loss)\n",
    "        self.acc_training.append(acc)        \n",
    "\n",
    "        \n",
    "    def validation_step(self, batch):\n",
    "        x, y = batch\n",
    "        \n",
    "        label=torch.tensor(y[:,0], dtype=torch.int64)\n",
    "        #targets=y[:,1:5]\n",
    "        #print('val:x,y', x.shape, y.shape)\n",
    "        #print('type',type(x), type(y))\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss_fn(logits,y)\n",
    "        acc = self.accuracy_calc(logits[0][:,1], label)\n",
    "        #loss = self.loss_fn(logits,y[:,0])\n",
    "        #loss = self.loss_fn_regression(logits,targets)\n",
    "        #acc = self.accuracy_calc(logits, y[:,0])\n",
    "        self.loss_valid.append(loss)\n",
    "        self.acc_valid.append(acc)\n",
    "\n",
    "    \n",
    "    def test_step(self, batch):\n",
    "        x, y = batch\n",
    "        label=torch.tensor(y[:,0], dtype=torch.int64)\n",
    "        #targets=y[:,1:5]\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss_fn(logits,y)\n",
    "        acc = self.accuracy_calc(x[1], label)\n",
    "        \n",
    "        #loss = self.loss_fn(logits,y[:,0])\n",
    "        #loss = self.loss_fn_regression(logits,targets)\n",
    "        #acc = self.accuracy_calc(logits, y[:,0])\n",
    "\n",
    "    \n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        avg_loss = torch.stack(self.loss_training).mean()\n",
    "        avg_acc = torch.stack(self.acc_training).mean()\n",
    "        self.loss_training.clear()\n",
    "        self.acc_training.clear()\n",
    "        #print('train_loss:', avg_loss, 'train_acc', avg_acc)\n",
    "        self.loss_training_epoch.append(avg_loss)\n",
    "        self.acc_training_epoch.append(avg_acc)\n",
    "        self.log('loss/train',avg_loss)\n",
    "        self.log('acc/train',avg_acc)\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        avg_loss = torch.stack(self.loss_valid).mean()\n",
    "        avg_acc = torch.stack(self.acc_valid).mean()\n",
    "        self.loss_valid.clear()\n",
    "        self.acc_valid.clear()\n",
    "        self.loss_valid_epoch.append(avg_loss)\n",
    "        self.acc_valid_epoch.append(avg_acc)\n",
    "        self.log('loss/valid',avg_loss)\n",
    "        self.log('acc/valid',avg_acc)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer =  optim.Adam(self.parameters(), lr=self.lr_rate, weight_decay = 1e-4)\n",
    "        lr_scheduler = {'scheduler': optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9), 'name': 'exp_LR'}\n",
    "        return [optimizer], [lr_scheduler]\n",
    "        #return optim.Adam(self.model.parameters(), lr=0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4. Logger ##\n",
    "Tensorboard logger is used. A window of tensorboard opens here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "logger = TensorBoardLogger(save_dir='./tb_logs/', name = 'HK')\n",
    "\n",
    "\n",
    "#%reload_ext tensorboard\n",
    "#%tensorboard --logdir=./tb_logs/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5. Build & fit a model ##\n",
    "Select whether to use `MLP()` or `CNNs2D()` for the model. The settings for the learning is described here.\n",
    "* `lr_rate`: learning rate\n",
    "* `batch_size`\n",
    "* `max_epochs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_core = CNNs2D() # or MLP()\n",
    "#model_core = MLP()\n",
    "model = PLModuleMNIST(model = model_core, lr_rate=0.0005)\n",
    "dm = HKDataset(batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type           | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model         | CNNs2D         | 34.6 M | train\n",
      "1 | accuracy_calc | BinaryAccuracy | 0      | train\n",
      "2 | focal_loss    | FocalLoss      | 0      | train\n",
      "---------------------------------------------------------\n",
      "34.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "34.6 M    Total params\n",
      "138.285   Total estimated model params size (MB)\n",
      "54        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d645d9a7285437f860d5487a6a06b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54690/1086953837.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label=torch.tensor(y[:,0], dtype=torch.int64)\n",
      "/tmp/ipykernel_54690/1086953837.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_class=torch.tensor(y[:,0], dtype=torch.int64)\n",
      "/home/edward/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (40) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c614736eea46fa9416d65534c63891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54690/1086953837.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label=torch.tensor(y[:,0], dtype=torch.int64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6c90048b43452aaee1470e4bb308ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:47\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:575\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    569\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    570\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    571\u001b[39m     ckpt_path,\n\u001b[32m    572\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    573\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    574\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:982\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m    979\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    980\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m    986\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1026\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:322\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m             batch_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmanual_optimization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[38;5;28mself\u001b[39m.batch_progress.increment_processed()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/manual.py:94\u001b[39m, in \u001b[36m_ManualOptimization.run\u001b[39m\u001b[34m(self, kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mStopIteration\u001b[39;00m):  \u001b[38;5;66;03m# no loop to break at this level\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m._restarting = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/manual.py:114\u001b[39m, in \u001b[36m_ManualOptimization.advance\u001b[39m\u001b[34m(self, kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# manually capture logged metrics\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m training_step_output = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m kwargs  \u001b[38;5;66;03m# release the batch from memory\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:323\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:391\u001b[39m, in \u001b[36mStrategy.training_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mtraining_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mPLModuleMNIST.training_step\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28mself\u001b[39m.manual_backward(loss)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[38;5;28mself\u001b[39m.loss_training.append(loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py:154\u001b[39m, in \u001b[36mLightningOptimizer.step\u001b[39m\u001b[34m(self, closure, **kwargs)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m._on_after_step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:239\u001b[39m, in \u001b[36mStrategy.optimizer_step\u001b[39m\u001b[34m(self, optimizer, closure, model, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl.LightningModule)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py:123\u001b[39m, in \u001b[36mPrecision.optimizer_step\u001b[39m\u001b[34m(self, optimizer, model, closure, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m closure = partial(\u001b[38;5;28mself\u001b[39m._wrap_closure, model, optimizer, closure)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:140\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    139\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/torch/optim/adam.py:218\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Perform a single optimization step.\u001b[39;00m\n\u001b[32m    213\u001b[39m \n\u001b[32m    214\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[33;03m    closure (Callable, optional): A closure that reevaluates the model\u001b[39;00m\n\u001b[32m    216\u001b[39m \u001b[33;03m        and returns the loss.\u001b[39;00m\n\u001b[32m    217\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cuda_graph_capture_health_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m loss = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/torch/optim/optimizer.py:420\u001b[39m, in \u001b[36mOptimizer._cuda_graph_capture_health_check\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;66;03m# Currently needed by Adam and AdamW\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_cuda_graph_capture_health_check\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    421\u001b[39m     \u001b[38;5;66;03m# Note [torch.compile x capturable]\u001b[39;00m\n\u001b[32m    422\u001b[39m     \u001b[38;5;66;03m# If we are compiling, we try to take the capturable path automatically by\u001b[39;00m\n\u001b[32m    423\u001b[39m     \u001b[38;5;66;03m# setting the flag to True during tracing. Due to this, we skip all the checks\u001b[39;00m\n\u001b[32m    424\u001b[39m     \u001b[38;5;66;03m# normally required for determining whether we can use CUDA graphs and\u001b[39;00m\n\u001b[32m    425\u001b[39m     \u001b[38;5;66;03m# shunt the responsibility to torch.inductor. This saves time during tracing\u001b[39;00m\n\u001b[32m    426\u001b[39m     \u001b[38;5;66;03m# since the checks are slow without sacrificing UX since inductor will warn\u001b[39;00m\n\u001b[32m    427\u001b[39m     \u001b[38;5;66;03m# later if CUDA graphs cannot be enabled, e.g.,\u001b[39;00m\n\u001b[32m    428\u001b[39m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/blob/d3ba8901d8640eb16f88b2bfef9df7fa383d4b47/torch/_inductor/compile_fx.py#L390.\u001b[39;00m\n\u001b[32m    429\u001b[39m     \u001b[38;5;66;03m# Thus, when compiling, inductor will determine if cudagraphs\u001b[39;00m\n\u001b[32m    430\u001b[39m     \u001b[38;5;66;03m# can be enabled based on whether there is input mutation or CPU tensors.\u001b[39;00m\n\u001b[32m    431\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    432\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m torch.compiler.is_compiling()\n\u001b[32m    433\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m torch.backends.cuda.is_built()\n\u001b[32m    434\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m torch.cuda.is_available()\n\u001b[32m    435\u001b[39m     ):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallbacks\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprogress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TQDMProgressBar\n\u001b[32m      4\u001b[39m runner = Trainer(max_epochs=\u001b[32m500\u001b[39m, \n\u001b[32m      5\u001b[39m                  \u001b[38;5;66;03m#gpus=[0],\u001b[39;00m\n\u001b[32m      6\u001b[39m                  accelerator=\u001b[33m'\u001b[39m\u001b[33mgpu\u001b[39m\u001b[33m'\u001b[39m,  \u001b[38;5;66;03m# or 'gpu', 'auto'\u001b[39;00m\n\u001b[32m      7\u001b[39m                  devices = \u001b[32m1\u001b[39m,\n\u001b[32m      8\u001b[39m                  logger=logger, \n\u001b[32m      9\u001b[39m                  callbacks=[TQDMProgressBar(refresh_rate=\u001b[32m10\u001b[39m)])\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:539\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28mself\u001b[39m.state.status = TrainerStatus.RUNNING\n\u001b[32m    538\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HK_Project/myenv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:64\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     63\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     67\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "\n",
    "runner = Trainer(max_epochs=500, \n",
    "                 #gpus=[0],\n",
    "                 accelerator='gpu',  # or 'gpu', 'auto'\n",
    "                 devices = 1,\n",
    "                 logger=logger, \n",
    "                 callbacks=[TQDMProgressBar(refresh_rate=10)])\n",
    "\n",
    "\n",
    "runner.fit(model, dm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6. Check the trained model ##\n",
    "* Structure of the model\n",
    "* Classification performance for the test dataset\n",
    "* Feature maps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step6-1. Structure of the trained model ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can load the trained model at the specific checkpoint\n",
    "#model = PLModuleMNIST.load_from_checkpoint(model=model_core, lr_rate=0.001, checkpoint_path='tb_logs/HK/version_30/checkpoints/epoch=468-step=37051.ckpt')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "#dm.setup() # when you load the model from a checkpoint\n",
    "\n",
    "labels_targets = []\n",
    "#outputs = []\n",
    "outputs_class = []\n",
    "outputs_targets = []\n",
    "for batch in dm.test_dataloader():\n",
    "    x, y = batch \n",
    "    \n",
    "    outputs = model.model(x)\n",
    "    out_class = outputs[0].to('cpu').detach()\n",
    "    out_targets =  outputs[1].to('cpu').detach()\n",
    "    outputs_class.append(out_class)\n",
    "    outputs_targets.append(out_targets)\n",
    "    labels_targets.append(y.to('cpu').detach())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_targets=np.vstack(labels_targets)\n",
    "outputs_class=np.vstack(outputs_class)\n",
    "outputs_targets=np.vstack(outputs_targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.save(labels_targets, '128test_labels_targets.pt')\n",
    "torch.save(outputs_class, '128test_outputs_class.pt')\n",
    "torch.save(outputs_targets, '128test_outputs_targets.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step6-2. Classification perfromance for the test dataset ####\n",
    "`Loss` and `Accuracy` are useful metrics for understanding the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss_train = [i.to('cpu').detach().numpy() for i in model.loss_training_epoch]\n",
    "loss_valid = [i.to('cpu').detach().numpy() for i in model.loss_valid_epoch]\n",
    "\n",
    "plt.plot(loss_train, label='train')\n",
    "plt.plot(loss_valid, label='valid')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "#plt.ylim([None, 1])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc_train = [i.to('cpu').detach().numpy() for i in model.acc_training_epoch]\n",
    "acc_valid = [i.to('cpu').detach().numpy() for i in model.acc_valid_epoch]\n",
    "\n",
    "plt.plot(acc_train, label='train')\n",
    "plt.plot(acc_valid, label='valid')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "#plt.ylim([None, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
